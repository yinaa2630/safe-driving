import 'package:audioplayers/audioplayers.dart';
import 'package:flutter/material.dart';
import 'package:camera/camera.dart';
import 'package:flutter_demo/service/face_mesh_service.dart';
import 'package:flutter_demo/service/tflite_service.dart';
import 'package:flutter_demo/utils/camera_utils.dart';
import 'package:google_mlkit_face_mesh_detection/google_mlkit_face_mesh_detection.dart';

class DrowsinessScreen extends StatefulWidget {
  final CameraDescription camera;

  const DrowsinessScreen({super.key, required this.camera});

  @override
  State<DrowsinessScreen> createState() => _DrowsinessScreenState();
}

class _DrowsinessScreenState extends State<DrowsinessScreen> {
  late CameraController _controller;
  final FaceMeshService _meshService = FaceMeshService();
  final TFLiteService _tfLiteService = TFLiteService();
  final AudioPlayer _audioPlayer = AudioPlayer();

  bool _isProcessing = false;
  double _currentEAR = 0.0; // face mesh ì—ì„œ íŒë‹¨í•œ EAR ì§€ìˆ˜
  double _drowsyScore = 0.0; // ëª¨ë¸ì´ íŒë‹¨í•œ ì¡¸ìŒ í™•ë¥ 
  bool _isDrowsy = false;
  DateTime? _closedStartTime;
  DateTime? _lastProcessTime;

  // ëˆˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (ê³ ì •ê°’)
  final List<int> _leftEyeIdx = [160, 144, 158, 153, 33, 133];
  final List<int> _rightEyeIdx = [385, 380, 387, 373, 263, 362];

  @override
  void initState() {
    super.initState();
    _audioPlayer.setVolume(1.0);
    _initCamera();
  }

  void _playBeep() async {
    try {
      // ì—ë®¬ë ˆì´í„° ë¶€í•˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì¬ìƒ ì „ ëª¨ë“œ ê³ ì •
      await _audioPlayer.setPlayerMode(PlayerMode.lowLatency);
      await _audioPlayer.play(AssetSource('sound/beep.mp3'));
      debugPrint("ğŸ”” ë¹„í”„ìŒ ì¬ìƒ ëª…ë ¹ ì „ì†¡ë¨");
    } catch (e) {
      debugPrint("âŒ ë¹„í”„ìŒ ì¬ìƒ ì—ëŸ¬: $e");
    }
  }

  void _stopBeep() async {
    await _audioPlayer.stop();
  }

  /// ì¹´ë©”ë¼ ì´ˆê¸°í™” ë° ìŠ¤íŠ¸ë¦¼ ì‹œì‘
  void _initCamera() async {
    _controller = CameraController(
      widget.camera,
      ResolutionPreset.low,
      enableAudio: false,
      imageFormatGroup: ImageFormatGroup.yuv420,
    );

    try {
      await _controller.initialize();
      if (!mounted) return;

      // 2. ì¹´ë©”ë¼ê°€ ì•ˆì •ì ìœ¼ë¡œ ëœ¬ í›„ì— ëª¨ë¸ ë¡œë“œ (ë¹„ë™ê¸°)
      await _tfLiteService.loadModel();

      setState(() {});
      _controller.startImageStream(_processCameraImage);
    } catch (e) {
      debugPrint("ì¹´ë©”ë¼ ì´ˆê¸°í™” ì—ëŸ¬: $e");
    }
  }

  /// ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ì²˜ë¦¬ ë£¨í”„
  void _processCameraImage(CameraImage image) async {
    if (_isProcessing) return;

    // ğŸ’¡ 150ms(ì•½ 0.5ì´ˆ) ë§ˆë‹¤ í•œ ë²ˆì”©ë§Œ ì²˜ë¦¬í•˜ë„ë¡ ì œí•œ
    final now = DateTime.now();
    if (_lastProcessTime != null &&
        now.difference(_lastProcessTime!).inMilliseconds < 500) {
      return;
    }
    _lastProcessTime = now;

    _isProcessing = true;

    try {
      // í™”ë©´ ë©ˆì¶¤ ë°©ì§€ë¥¼ ìœ„í•œ í•œ í”„ë ˆì„ ì–‘ë³´
      await Future.delayed(Duration.zero);

      // 1. ì´ë¯¸ì§€ ë³€í™˜ (CameraUtils ì‚¬ìš©)
      final inputImage = CameraUtils.convertCameraImageToInputImage(
        image,
        widget.camera,
      );

      // 2. ì–¼êµ´ ë©”ì‹œ ê°ì§€ (FaceMeshService ì‚¬ìš©)
      final meshes = await _meshService.detectMesh(inputImage);

      if (meshes.isNotEmpty) {
        final mesh = meshes.first;

        // 3. EAR ê³„ì‚° (CameraUtils ì‚¬ìš©)
        final leftEAR = CameraUtils.calculateEAR(mesh.points, _leftEyeIdx);
        final rightEAR = CameraUtils.calculateEAR(mesh.points, _rightEyeIdx);
        final avgEAR = (leftEAR + rightEAR) / 2;

        // 4. TFLite ëª¨ë¸ ì˜ˆì¸¡ ì¶”ê°€
        // --- ì¶”ê°€ëœ ì¢Œí‘œ ë³€í™˜ ë¡œì§ ---
        // ëª¨ë¸ í•™ìŠµ ê¸°ì¤€: 720 x 1280
        const double targetWidth = 720.0;
        const double targetHeight = 1280.0;

        // í˜„ì¬ ì¹´ë©”ë¼ ì´ë¯¸ì§€ í•´ìƒë„ (ì˜ˆ: 1080, 1920 ë“±)
        final double currentWidth = image.width.toDouble();
        final double currentHeight = image.height.toDouble();

        // ì¢Œí‘œ ìŠ¤ì¼€ì¼ë§: í˜„ì¬ ì¢Œí‘œ * (íƒ€ê²Ÿ í•´ìƒë„ / í˜„ì¬ í•´ìƒë„)
        // List<FaceMeshPoint> íƒ€ì…ì„ ìœ ì§€í•˜ë©° ë‚´ë¶€ ê°’ë§Œ ë³€ê²½
        final List<FaceMeshPoint> scaledPoints = mesh.points.map((pt) {
          return FaceMeshPoint(
            index: pt.index,
            x: pt.x * (targetWidth / currentWidth),
            y: pt.y * (targetHeight / currentHeight),
            // ë§Œì•½ zì¶•(ê¹Šì´)ì´ë‚˜ ë‹¤ë¥¸ ì†ì„±ì´ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ë³µì‚¬
            z: pt.z,
          );
        }).toList();
        // -------------------------

        // ë³€í™˜ëœ scaledPointsë¥¼ ëª¨ë¸ì— ì „ë‹¬
        final score = _tfLiteService.predict(
          scaledPoints,
          targetWidth, // ì´ì œ í•­ìƒ 720
          targetHeight, // ì´ì œ í•­ìƒ 1280
        );

        // 5. ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ì¡¸ìŒ íŒì •
        _updateUI(avgEAR, score);
      }
    } catch (e) {
      debugPrint("ë¶„ì„ ì—ëŸ¬: $e");
    } finally {
      _isProcessing = false;
    }
  }

  /// EAR ìˆ˜ì¹˜ ì—…ë°ì´íŠ¸ ë° 2ì´ˆ ì¡¸ìŒ íŒì • ë¡œì§
  void _updateUI(double ear, double? score) async {
    const double earThreshold = 0.21; // ear íŒë‹¨ ê¸°ì¤€ê°’
    const double modelThreshold = 0.5; // TFLite ì¡¸ìŒ ê¸°ì¤€ê°’
    setState(() {
      _currentEAR = ear;
      if (score != null) _drowsyScore = score;
    });

    // 1. EAR íŒì • (2ì´ˆ ì§€ì†ë˜ì–´ì•¼ í•¨)
    bool isEarClosed = (ear < earThreshold);
    if (isEarClosed) {
      _closedStartTime ??= DateTime.now(); // ì²˜ìŒ ëˆˆ ê°ì•˜ì„ ë•Œ ì‹œê°„ ê¸°ë¡
    } else {
      _closedStartTime = null; // ëˆˆ ëœ¨ë©´ ì´ˆê¸°í™”
    }

    // EARì´ 2ì´ˆ ì´ìƒ ìœ ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸
    bool earDrowsy =
        _closedStartTime != null &&
        DateTime.now().difference(_closedStartTime!).inSeconds >= 2;

    // 2. ëª¨ë¸ íŒì • (ëª¨ë¸ì€ ìˆœê°„ì ì¸ íŒë‹¨ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ì¦‰ì‹œ ë°˜ì˜í•˜ê±°ë‚˜ ì§§ì€ ì§€ì† ì‹œê°„)
    // ì—¬ê¸°ì„œëŠ” ëª¨ë¸ ì ìˆ˜ê°€ ê¸°ì¤€ì¹˜ë¥¼ ë„˜ì—ˆì„ ë•Œë¥¼ 'ì¡¸ìŒ'ìœ¼ë¡œ ë´…ë‹ˆë‹¤.
    bool modelDrowsy = (score != null && score > modelThreshold);

    // 3. ìµœì¢… ê²°í•© (OR ì¡°ê±´)
    // EARì´ 2ì´ˆ ì´ìƒ ë‚®ê±°ë‚˜, ëª¨ë¸ì´ ì¡¸ìŒì´ë¼ê³  íŒë‹¨í•˜ë©´ ê²½ê³ !
    if (earDrowsy || modelDrowsy) {
      if (!_isDrowsy) {
        setState(() => _isDrowsy = true);
        _playBeep();
      }
    } else {
      if (_isDrowsy) {
        _stopBeep();
        setState(() => _isDrowsy = false);
      }
    }
  }

  @override
  void dispose() {
    _controller.dispose();
    _meshService.dispose();
    _tfLiteService.dispose();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    if (!_controller.value.isInitialized) {
      return const Scaffold(body: Center(child: CircularProgressIndicator()));
    }

    // í™”ë©´ì˜ ê°€ë¡œì„¸ë¡œ í¬ê¸°
    final size = MediaQuery.of(context).size;

    return Scaffold(
      backgroundColor: Colors.black,
      body: Stack(
        fit: StackFit.expand,
        children: [
          // --- 1. ì¹´ë©”ë¼ í”„ë¦¬ë·° ë ˆì´ì–´ (íšŒì „ ë° ëŠ˜ì–´ì§ ë°©ì§€) ---
          SizedBox(
            width: size.width,
            height: size.height,
            child: FittedBox(
              fit: BoxFit.cover, // í™”ë©´ ë¹„ìœ¨ì— ë§ì¶° ìë¥´ê³  ê½‰ ì±„ì›€ (ëŠ˜ì–´ì§ ë°©ì§€)
              child: SizedBox(
                // ì¹´ë©”ë¼ì˜ í•´ìƒë„ ë¹„ìœ¨ì— ë§ì¶˜ ë°•ìŠ¤ ìƒì„±
                width: _controller.value.previewSize!.height,
                height: _controller.value.previewSize!.width,
                child: RotatedBox(
                  quarterTurns: 0,
                  child: CameraPreview(_controller),
                ),
              ),
            ),
          ),

          // --- 2. ì‹¤ì‹œê°„ EAR ìˆ˜ì¹˜ & ëª¨ë¸ ì¡¸ìŒ ìˆ˜ì¹˜ í‘œì‹œ ---
          Positioned(
            top: 60,
            left: 20,
            child: Column(
              // Columnì„ ì‚¬ìš©í•˜ì—¬ ì„¸ë¡œë¡œ ë‚˜ì—´í•©ë‹ˆë‹¤.
              crossAxisAlignment: CrossAxisAlignment.start,
              children: [
                Container(
                  padding: const EdgeInsets.all(12),
                  decoration: BoxDecoration(
                    color: Colors.black.withValues(alpha: 0.6),
                    borderRadius: BorderRadius.circular(8),
                  ),
                  child: Text(
                    "EAR: ${_currentEAR.toStringAsFixed(3)}",
                    style: const TextStyle(
                      color: Colors.white,
                      fontSize: 22,
                      fontWeight: FontWeight.bold,
                    ),
                  ),
                ),
                const SizedBox(height: 10), // ê°„ê²© ì¶”ê°€
                Container(
                  padding: const EdgeInsets.all(12),
                  decoration: BoxDecoration(
                    color: Colors.blue.withValues(
                      alpha: 0.6,
                    ), // ëª¨ë¸ ì ìˆ˜ëŠ” íŒŒë€ìƒ‰ìœ¼ë¡œ êµ¬ë¶„í•´ë³¼ê¹Œìš”?
                    borderRadius: BorderRadius.circular(8),
                  ),
                  child: Text(
                    "Model: ${_drowsyScore.toStringAsFixed(3)}", // ë³€ìˆ˜ëª… ìˆ˜ì • í™•ì¸!
                    style: const TextStyle(
                      color: Colors.white,
                      fontSize: 22,
                      fontWeight: FontWeight.bold,
                    ),
                  ),
                ),
              ],
            ),
          ),

          // --- 3. ì¡¸ìŒ ê²½ê³  ì˜¤ë²„ë ˆì´ ---
          if (_isDrowsy)
            Container(
              color: Colors.red.withValues(alpha: 0.6),
              child: const Center(
                child: Text(
                  "ì¡¸ìŒ ê²½ê³ !!",
                  style: TextStyle(
                    fontSize: 48,
                    color: Colors.white,
                    fontWeight: FontWeight.bold,
                  ),
                ),
              ),
            ),
        ],
      ),
    );
  }
}
